{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw=pd.read_csv('./data/MNIST/mnist_train.csv').astype('float32')\n",
    "test_data_raw=pd.read_csv('./data/MNIST/mnist_test.csv').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=train_data_raw['label'].values\n",
    "train_img=train_data_raw.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing data\n"
     ]
    }
   ],
   "source": [
    "null_bool=train_img.isnull().to_numpy()\n",
    "a=np.ones((784,1))\n",
    "nullz=np.sum(np.dot(null_bool,a))\n",
    "if nullz:\n",
    "    print('there is missing data')\n",
    "else:\n",
    "    print('no missing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_img=train_img.values/255\n",
    "\n",
    "test_img=test_data_raw.values/255\n",
    "all_img=np.concatenate((train_img, test_img), axis=0)\n",
    "\n",
    "train_img=train_img.reshape(-1,1,28,28)\n",
    "test_img=test_img.reshape(-1,1,28,28)\n",
    "all_img=all_img.reshape(-1,1,28,28)\n",
    "print(all_img.shape)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.RandomResizedCrop(28,scale=(0.85, 1.0)),\n",
    "                        transforms.RandomAffine(15, translate=(0.15,0.15))\n",
    "                        \n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img, val_img, train_label, val_label = train_test_split(train_img, train_label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pic should be 2/3 dimensional. Got 4 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-73393b305513>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtf_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pic should be 2/3 dimensional. Got {} dimensions.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pic should be 2/3 dimensional. Got 4 dimensions."
     ]
    }
   ],
   "source": [
    "tf_img=np.zeros((train_img.shape))\n",
    "print(tf_img[0].shape)\n",
    "print(transform(train_img))\n",
    "for i in range(train_img.shape[0]):\n",
    "    tf_img[i]=transform(train_img[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84000, 1, 28, 28) (84000,)\n"
     ]
    }
   ],
   "source": [
    "train_imgs=np.vstack((train_img,tf_img))\n",
    "train_lab=np.hstack((train_label,train_label))\n",
    "print(train_imgs.shape, train_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84000, 1, 28, 28) (84000,) (28000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_imgs.shape, train_lab.shape, test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img, val_img, train_label, val_label = train_test_split(train_imgs, train_lab, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, train_label=T.from_numpy(train_imgs).type(T.FloatTensor), T.from_numpy(train_lab).type(T.LongTensor)\n",
    "# train_img, train_label=T.from_numpy(train_img).type(T.FloatTensor), T.from_numpy(train_label).type(T.LongTensor)\n",
    "# val_img, val_label=T.from_numpy(val_img).type(T.FloatTensor), T.from_numpy(val_label).type(T.LongTensor)\n",
    "test_img=T.from_numpy(test_img).type(T.FloatTensor)\n",
    "\n",
    "# print(val_img.size(), val_label.size(), train_img.shape, train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_img.shape, train_label.shape, test_img.shape)\n",
    "# print(train_img.shape, train_label.shape, val_img.shape, val_label.shape,test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,3))\n",
    "fig, axs = plt.subplots(4,3)\n",
    "fig.suptitle('Vertically stacked subplots')\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axs[i,j].imshow(train_img[(i*3+j)*8,:][0], cmap='gray')\n",
    "for i in range(2,4):\n",
    "    for j in range(3):\n",
    "        axs[i,j].imshow(tf_img[((i-2)*3+j)*8,:][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class DopeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DopeNet, self).__init__()\n",
    "        \n",
    "        self.fc1= nn.Linear(784, 128)\n",
    "        self.dropout= nn.Dropout(0.2)\n",
    "        self.fc2= nn.Linear(128,96)\n",
    "        self.fc3= nn.Linear(96, 10)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_x):\n",
    "        x = F.relu(self.fc1(input_x))\n",
    "        x = F.relu(self.dropout(self.fc2(x)))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model=DopeNet().to('cuda')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DopeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DopeNet, self).__init__()\n",
    "        \n",
    "        self.conv1= nn.Conv2d(1, 16, 5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2= nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.fc1= nn.Linear(32*7*7,128)\n",
    "        self.fc2= nn.Linear(128,64)\n",
    "        self.fc3= nn.Linear(64, 10)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_x):\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(input_x))),2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))),2)\n",
    "        x = x.view(-1,32*7*7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model=DopeNet().to('cuda')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###HYPERPARAMETER\n",
    "n_epoch=30\n",
    "batch_size=128\n",
    "\n",
    "train = T.utils.data.TensorDataset(train_img, train_label)\n",
    "# train = T.utils.data.TensorDataset(train_img, tr_label)\n",
    "# val = T.utils.data.TensorDataset(val_img, val_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,3))\n",
    "plt.imshow(train_img[1][0], cmap='gray')\n",
    "plt.show()\n",
    "fig = plt.figure(figsize=(6,3))\n",
    "plt.imshow(tf_img[1][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloader\n",
    "train_loader= T.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "# val_loader= T.utils.data.DataLoader(val, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###HYPERPARAMETER\n",
    "lr=0.0075\n",
    "betas=(0.9,0.999)\n",
    "momentum=0.9\n",
    "decay_rate=0.95\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "# optimizer=optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "optimizer=optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "# lr_sched = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
    "lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train loop\n",
    "count=0\n",
    "loss_list=[]\n",
    "val_list=[]\n",
    "iteration=[]\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    model.train()\n",
    "    for j, (img, label) in enumerate(train_loader):\n",
    "        img = img.to('cuda')\n",
    "        label = label.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output=model(img)\n",
    "        loss=criterion(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count+=1    \n",
    "        \n",
    "        if count%50 == 0:\n",
    "            correct=0\n",
    "            total=0\n",
    "            model.eval()\n",
    "            for images, labels in val_loader:\n",
    "                with T.no_grad():\n",
    "                    images=images.to('cuda')\n",
    "                    labels=labels.to('cuda')\n",
    "                    outputs=model(images)\n",
    "                    val_loss=criterion(outputs,labels)\n",
    "                    pred=T.max(outputs.data, 1)[1]\n",
    "                    total+=len(labels)\n",
    "#                 print(len(images), len(labels), len(pred))\n",
    "                    correct += (pred == labels).sum()\n",
    "            accuracy = 100.0 * float(correct) / float(total)\n",
    "            loss_list.append(loss.item())\n",
    "            val_list.append(val_loss.item())\n",
    "            iteration.append(count)\n",
    "    lr_sched.step()\n",
    "            \n",
    "\n",
    "    print('Epoch {} - Training Loss: {} | Val Loss:{} |  Val Accuracy:{}'.format(i, loss.item(), val_loss.item(),accuracy))\n",
    "#     print('Epoch {} - Training Loss: {} | Val Loss: |  Val Accuracy:'.format(i, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=test_img[5][0]\n",
    "plt.imshow(data, cmap='gray')\n",
    "test_data=T.tensor(data).view(-1,1,28,28)\n",
    "\n",
    "with T.no_grad():\n",
    "    test_data=test_img.to('cuda')\n",
    "    logps = model(test_data)\n",
    "\n",
    "    \n",
    "ps = T.exp(logps)\n",
    "ps=ps.cpu()\n",
    "probab = list(ps.numpy()[0])\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(iteration,loss_list)\n",
    "# plt.plot(iteration,val_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Logistic Regression: Loss vs Number of iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(model.state_dict(), 'mnist_inf_mj.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T.save(model, 'mnist_mj_mod.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = T.utils.data.TensorDataset(test_img)\n",
    "print(test_img.shape)\n",
    "test_loader= T.utils.data.DataLoader(test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=[]\n",
    "model.eval()\n",
    "for [images] in test_loader:\n",
    "    with T.no_grad():\n",
    "        images=images.to('cuda')\n",
    "        outputs=model(images)\n",
    "        pred=T.max(outputs.data, 1)[1]\n",
    "        predicts.append(pred.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predicts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = range(1,28001)\n",
    "print(id[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(id,predicts)), columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('mj_mnist_cnn_6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
